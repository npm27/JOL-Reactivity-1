nomiss$Direction == "S")
nomiss.u = subset(nomiss,
nomiss$Direction == "U")
##get rounded jols
nomiss.f$jol_bin = round(nomiss.f$Jol, -1)
nomiss.b$jol_bin = round(nomiss.b$Jol, -1)
nomiss.s$jol_bin = round(nomiss.s$Jol, -1)
nomiss.u$jol_bin = round(nomiss.u$Jol, -1)
##put data in wide format
##jol
f.jol = cast(nomiss.f, Subject ~ block, mean, value = 'Jol')
f.jol$mean_JOL = apply(f.jol, 1, mean)
f.jol$jol_bin = round(f.jol$mean_JOL, -1)
b.jol = cast(nomiss.b, Subject ~ block, mean, value = 'Jol')
b.jol$mean_JOL = apply(b.jol, 1, mean)
b.jol$jol_bin = round(b.jol$mean_JOL, -1)
s.jol = cast(nomiss.s, Subject ~ block, mean, value = 'Jol')
s.jol$mean_JOL = apply(s.jol, 1, mean)
s.jol$jol_bin = round(s.jol$mean_JOL, -1)
u.jol = cast(nomiss.u, Subject ~ block, mean, value = 'Jol')
u.jol$mean_JOL = apply(u.jol, 1, mean)
u.jol$jol_bin = round(u.jol$mean_JOL, -1)
##recall
f.recall = cast(nomiss.f, Subject ~ block, mean, value = 'Recall')
f.recall$mean_recall = apply(f.recall, 1, mean)
b.recall = cast(nomiss.b, Subject ~ block, mean, value = 'Recall')
b.recall$mean_recall = apply(b.recall, 1, mean)
s.recall = cast(nomiss.s, Subject ~ block, mean, value = 'Recall')
s.recall$mean_recall = apply(s.recall, 1, mean)
u.recall = cast(nomiss.u, Subject ~ block, mean, value = 'Recall')
u.recall$mean_recall = apply(u.recall, 1, mean)
##add direction column
f.recall$direction = rep("f", 28)
f.jol$direction = rep("f", 28)
b.recall$direction = rep("b", 28)
b.jol$direction = rep("b", 28)
s.recall$direction = rep("s", 28)
s.jol$direction = rep("s", 28)
u.recall$direction = rep("u", 28)
u.jol$direction = rep("u", 28)
##Put everything back together
int.recall = rbind(f.recall, b.recall, s.recall, u.recall)
int.jol = rbind(f.jol, b.jol, s.jol, u.jol)
int.recall = int.recall[ , -c(2:3)]
int.jol = int.jol[ , -c(2:3)]
int.dat = cbind(int.jol, int.recall)
int.dat = int.dat[ , -c(4:5)]
##get difference score
int.dat$mean_recall = int.dat$mean_recall * 100
int.dat$diff = int.dat$jol_bin - int.dat$mean_recall
library(car)
model9 = aov(int.dat$diff ~ (int.dat$jol_bin*int.dat$direction))
summary(model9)
library(lsr)
etas1 = etaSquared(model9)
bar3 = ggplot(long.dat, aes(Direction, Score, fill = Task))
bar3 = bar3 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol" = "white",
"Recall" = "dimgrey")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance")
ylim(0,100)
#labs(title="All Blocks")
bar3
dat = read.csv("ex2 final output.csv")
summary(dat)
library(ggplot2)
library(reshape)
##put recall on correct scale
dat$Scored_Response = (dat$Scored_Response * 100)
##remove out of range scores
dat$Jol_Response[dat$Jol_Response > 100] = NA
##get sample size
summary(dat$Subject) #n = 34
summary(dat)
##remove missing
nomiss3 = na.omit(dat)
colnames(nomiss3)[6] = "Jol"
colnames(nomiss3)[9] = "Recall"
####make the graph####
##melt the data
long.dat = melt(nomiss3, id = c("Subject", "Block",
"ListNum", "Direction", "ExperimentName", "cue_target",
"recall_response", "cue_prompt"))
summary(long.dat)
colnames(long.dat)[9] = "Task"
colnames(long.dat)[10] = "Score"
bar3 = ggplot(long.dat, aes(Direction, Score, fill = Task))
bar3 = bar3 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol" = "white",
"Recall" = "dimgrey")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance")
ylim(0,100)
#labs(title="All Blocks")
bar3
bar3 = ggplot(long.dat, aes(Direction, Score, fill = Task))
bar3 = bar3 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol" = "white",
"Recall" = "dimgrey")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance") +
ylim(0,100)
#labs(title="All Blocks")
bar3
knitr::include_graphics("plot1.png")
citr:::insert_citation()
12.11*40
484.4*2
968.8*.15
968.8-145.32
823-110-50
85-22)
85-22
n = 100
dbinom(100)
dbinom(50, 100, 50)
dbinom(50, 100, 2)
dbinom(50, 100, .5)
dbinom(50, 100, .5)
round(data.frame(0:100, probs), digits = 5)
probs = dbinom(50, 100, .5)
round(data.frame(0:100, probs), digits = 5)
plot(0:100, probs, type="h", xlim=c(0,100), ylim=c(0,.1))
probs = dbinom(0:100, 100, .5) ##get the probability
round(data.frame(0:100, probs), digits = 5)
plot(0:100, probs, type="h", xlim=c(0,100), ylim=c(0,.1))
points(0:100, probs, pch=16, cex=.5)
curve(dnorm(x, mean=50, sd=5), from=0, to=100, xlim = c(0, 100), ylim = c(0, 0.5), xlab = "x", add=T, col="blue")
sum(dbinom(45:55, size=100, prob=1/2))
sum(dbinom(50, size=100, prob=1/2))
length(probs)
probs = as.data.frame(probs)
subset(probs, Mod(probs$probs) == 0)
View(probs)
head = 1
tail = 0
prob = e
e
e = exp(1)
sample(c("Heads", "Tails"), n, rep = T)
Flip1Coin = function(n) sample(c("Heads", "Tails"), n, rep = T)
Flip1Coin(n)
sample(c("Heads", "Tails"), n, rep = T)
sample(c("Heads", "Tails"), n, rep = 100)
Flip1Coin = function(n) sample(c("Heads", "Tails"), n, rep = 100)
Flip1Coin(n)
sample(c("Heads", "Tails"), n, rep = 100)
Flip1Coin = sample(c("Heads", "Tails"), n, rep = 100)
pbinom(50, 100, .5)
dbinom(50, 100, .5)
dnorm(50)
dnorm(50/sqrt(24))
pbinom(50, size = 100, .5)
pbinom(48, size = 100, .5)
pbinom(52, size = 100, .5)
pbinom(71, size = 100, .5)
m = 100 * .5
sd1 = sqrt(100 * .5 *.5)
1 - dnorm(50, mean = m, sd = sd1)
1 - pnorm(50, mean = m, sd = sd1)
x = c(0:100)
length(x)
mod(x, 2)
Mod(x)
Mod(x, 2)
.5*10
.75*7.5
.6*7.5
.7*7.5
.65*7.5
.68*7.5
.625*7.5
.667*7.5
.667*5
.667*4
.667*4.25
.667*8
.6 *8
.62 *8
.63 *8
.625 *8
.625 * 4
25*60
1500/5
install.packages("installr")
installr::installr()
library(ez)
library(reshape)
devtools::install_github("npm27/lrd")
devtools::install_github("npm27/lrd")
devtools::install_github("npm27/lrd")
shiny::runApp('GitHub/lrd/shiny')
shiny::runApp('lrdSHINY')
runApp('lrdSHINY')
runApp('lrdSHINY')
setwd("~/GitHub/CVOE-2021/1 YA/2 Analyses/3 Ex Gauss")
setwd("~/GitHub/CVOE-2021/1 YA")
setwd("~/GitHub/CVOE-2021")
##Install retimes from archive
url = "https://cran.r-project.org/src/contrib/Archive/retimes/retimes_0.1-2.tar.gz"
pkgFile = "retimes_0.1-2.tar.gz"
download.file(url = url, destfile = pkgFile)
install.packages(pkgs=pkgFile, type="source", repos=NULL)
unlink(pkgFile)
library(devtools)
install.packages("rtools")
install.packages("Rtools")
setwd("~/")
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
4.5+4.5+4.5+6+4.5+4.5
28.5*12.5
setwd("~/GitHub/JOL-Reactivity-1/3 Output and Analyses/2 Analyses/Ex 1B")
####JML EX 1 data####
##set up
#Read in data
JOL = read.csv("JOL_scored.csv")
Study = read.csv("Read_scored.csv")
View(JOL)
#Load libraries
library(ez)
library(reshape)
library(psychReport)
options(scipen = 999)
##Let's take a look at the data
summary(JOL)
summary(Study)
View(JOL)
colnames(JOL)[19] = "Response.JOL"
colnames(JOL)[6] = "Recall_Score"
colnames(Study)[6] = "Recall_Score"
colnames(JOL)[1:2] = c("thing", "thing2")
colnames(JOL)[6, 19] = c("thing", "thing2")
colnames(JOL)[[6, 19]] = c("thing", "thing2")
colnames(JOL)[1:2] = c("thing", "thing2", "thing3")
colnames(JOL)[1:3] = c("thing", "thing2", "thing3")
####JML EX 1 data####
##set up
#Read in data
JOL = read.csv("JOL_scored.csv")
Study = read.csv("Read_scored.csv")
#Load libraries
library(ez)
library(reshape)
library(psychReport)
options(scipen = 999)
##Let's take a look at the data
summary(JOL)
summary(Study)
colnames(JOL)[19] = "Response.JOL"
colnames(JOL)[6] = "Recall_Score"
colnames(Study)[6] = "Recall_Score"
#get JOLs and Recall on same scale
JOL$Recall_Score = JOL$Recall_Score * 100
Study$Recall_Score = Study$Recall_Score * 100
#Fix out of range JOLs
JOL$Response.JOL = as.numeric(JOL$Response.JOL)
JOL$Response.JOL[JOL$Response.JOL > 100] = NA
#Fix column names
colnames(JOL)[12] = "Direction"
colnames(Study)[12] = "Direction"
#how many participants are we starting w/?
length(unique(JOL$id)) #52
length(unique(Study$id)) #59
unique(JOL$id)
length(unique(Study$id)) #59
JOL[1, 1]
#Drop unused columns w/ indexing
JOL1 = JOL[ , -c(1, 3:5, 7:11, 13:18, 20:21)] #Will use this one for IOC
JOL2 = JOL[ , -c(1, 3:5, 7:11, 13:21)] #Will use this one for reactivity
JOL2$Task = rep("JOL")
View(JOL2)
Study = Study[ , -c(1, 3:5, 7:11, 13:18)]
Study$Task = rep("Study")
View(JOL2)
View(Study)
reactivity_data = rbind(Study, JOL2)
##get descriptives
##Jol
tapply(JOL1$Response.JOL, JOL1$Direction, mean, na.rm = T)
tapply(JOL2$Recall_Score, JOL2$Direction, mean, na.rm = T)
#Study
tapply(Study$Recall_Score, Study$Direction, mean, na.rm = T)
####Clean the data####
##First check for outliers
jols.ratings = cast(JOL1, id ~ Direction, mean, na.rm = T)
View(jols.ratings)
jols.ratings2 = scale(jols.ratings) #a few close ones, but no real outliers here
View(jols.ratings2)
#JOL group recall by direction
jols = cast(JOL1[ , c(1, 3, 4, 2)], id ~ Direction, mean, na.rm = T)
View(JOL1)
jols2 = scale(jols) #one in the unrelated #w10122668_asr
#Study group recall by direction
study = cast(Study[ , c(1, 3, 4, 2)], id ~ Direction, mean, na.rm = T)
study2 = scale(study) #got two: w10122762_blm, W10129411_WB
##Remove the outliers
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10122668_asr")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10122762_blm")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "W10129411_WB")
#remove from IOC
JOL1 = subset(JOL1,
JOL1$id != "w10122668_asr")
####JML EX 1 data####
##set up
#Read in data
JOL = read.csv("JOL_scored.csv")
Study = read.csv("Read_scored.csv")
#Load libraries
library(ez)
library(reshape)
library(psychReport)
options(scipen = 999)
##Let's take a look at the data
summary(JOL)
summary(Study)
colnames(JOL)[19] = "Response.JOL"
colnames(JOL)[6] = "Recall_Score"
colnames(Study)[6] = "Recall_Score"
#colnames(JOL)[1:3] = c("thing", "thing2", "thing3") #Rename multiple columns. Columns must be next to each other in the dataframe!
#get JOLs and Recall on same scale
JOL$Recall_Score = JOL$Recall_Score * 100
Study$Recall_Score = Study$Recall_Score * 100
#Fix out of range JOLs
JOL$Response.JOL = as.numeric(JOL$Response.JOL)
JOL$Response.JOL[JOL$Response.JOL > 100] = NA #> greater, < less, == equals, != not equal
#table(JOL$Response.JOL)
#Fix column names
colnames(JOL)[12] = "Direction"
colnames(Study)[12] = "Direction"
#how many participants are we starting w/?
length(unique(JOL$id)) #52
length(unique(Study$id)) #59
#Drop unused columns w/ indexing
JOL1 = JOL[ , -c(1, 3:5, 7:11, 13:18, 20:21)] #Will use this one for IOC
JOL2 = JOL[ , -c(1, 3:5, 7:11, 13:21)] #Will use this one for reactivity
JOL2$Task = rep("JOL")
Study = Study[ , -c(1, 3:5, 7:11, 13:18)]
Study$Task = rep("Study")
reactivity_data = rbind(Study, JOL2)
##get descriptives
##Jol
tapply(JOL1$Response.JOL, JOL1$Direction, mean, na.rm = T) #DV, IV (grouping variable), function, remove NAs
tapply(JOL2$Recall_Score, JOL2$Direction, mean, na.rm = T)
#Study
tapply(Study$Recall_Score, Study$Direction, mean, na.rm = T)
####Clean the data####
##First check for outliers
jols.ratings = cast(JOL1, id ~ Direction, mean, na.rm = T)
jols.ratings2 = scale(jols.ratings) #a few close ones, but no real outliers here
#JOL group recall by direction
jols = cast(JOL1[ , c(1, 3, 4, 2)], id ~ Direction, mean, na.rm = T)
jols2 = scale(jols) #one in the unrelated #w10122668_asr
#Study group recall by direction
study = cast(Study[ , c(1, 3, 4, 2)], id ~ Direction, mean, na.rm = T)
study2 = scale(study) #got two: w10122762_blm, W10129411_WB
##Remove the outliers
reactivity_data = subset(reactivity_data$id != "W10129411_WB" | reactivity_data$id != "w10122762_blm"
| reactivity_data$id != "w10122668_asr")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "W10129411_WB" | reactivity_data$id != "w10122762_blm"
| reactivity_data$id != "w10122668_asr")
##Remove the outliers
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10122668_asr")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10122762_blm")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "W10129411_WB")
####JML EX 1 data####
##set up
#Read in data
JOL = read.csv("JOL_scored.csv")
Study = read.csv("Read_scored.csv")
#Load libraries
library(ez)
library(reshape)
library(psychReport)
options(scipen = 999)
##Let's take a look at the data
summary(JOL)
summary(Study)
colnames(JOL)[19] = "Response.JOL"
colnames(JOL)[6] = "Recall_Score"
colnames(Study)[6] = "Recall_Score"
#colnames(JOL)[1:3] = c("thing", "thing2", "thing3") #Rename multiple columns. Columns must be next to each other in the dataframe!
#get JOLs and Recall on same scale
JOL$Recall_Score = JOL$Recall_Score * 100
Study$Recall_Score = Study$Recall_Score * 100
#Fix out of range JOLs
JOL$Response.JOL = as.numeric(JOL$Response.JOL)
JOL$Response.JOL[JOL$Response.JOL > 100] = NA #> greater, < less, == equals, != not equal
#table(JOL$Response.JOL)
#Fix column names
colnames(JOL)[12] = "Direction"
colnames(Study)[12] = "Direction"
#how many participants are we starting w/?
length(unique(JOL$id)) #52
length(unique(Study$id)) #59
#Drop unused columns w/ indexing
JOL1 = JOL[ , -c(1, 3:5, 7:11, 13:18, 20:21)] #Will use this one for IOC
JOL2 = JOL[ , -c(1, 3:5, 7:11, 13:21)] #Will use this one for reactivity
JOL2$Task = rep("JOL")
Study = Study[ , -c(1, 3:5, 7:11, 13:18)]
Study$Task = rep("Study")
reactivity_data = rbind(Study, JOL2)
##get descriptives
##Jol
tapply(JOL1$Response.JOL, JOL1$Direction, mean, na.rm = T) #DV, IV (grouping variable), function, remove NAs
tapply(JOL2$Recall_Score, JOL2$Direction, mean, na.rm = T)
#Study
tapply(Study$Recall_Score, Study$Direction, mean, na.rm = T)
####Clean the data####
##First check for outliers
jols.ratings = cast(JOL1, id ~ Direction, mean, na.rm = T)
jols.ratings2 = scale(jols.ratings) #a few close ones, but no real outliers here
#JOL group recall by direction
jols = cast(JOL1[ , c(1, 3, 4, 2)], id ~ Direction, mean, na.rm = T)
jols2 = scale(jols) #one in the unrelated #w10122668_asr
#Study group recall by direction
study = cast(Study[ , c(1, 3, 4, 2)], id ~ Direction, mean, na.rm = T)
study2 = scale(study) #got two: w10122762_blm, W10129411_WB
reactivity_data = subset(reactivity_data,
reactivity_data$id != "W10129411_WB" & reactivity_data$id != "w10122762_blm"
& reactivity_data$id != "w10122668_asr")
#remove from IOC
JOL1 = subset(JOL1,
JOL1$id != "w10122668_asr")
##remove anyone else w/ abysmal related recall (suggests not paying attention) or really high unrelated (suggests cheating)
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w881414_BAC")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10056248bs")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10094784")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10095166_RS")
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10107404_zeb")
#remove from IOC dataset
JOL1 = subset(JOL1,
JOL1$id != "w881414_BAC")
#remove participants who didn't take JOL task seriously
reactivity_data = subset(reactivity_data,
reactivity_data$id != "w10050706")
JOL1 = subset(JOL1,
JOL1$id != "w10050706")
#drop na's and get means again
JOL1 = na.omit(JOL1)
reactivity_data = na.omit(reactivity_data)
##IOC
tapply(JOL1$Response.JOL, JOL1$Direction, mean)
tapply(JOL1$Recall_Score, JOL1$Direction, mean)
##Reactivity
tapply(reactivity_data$Recall_Score, list(reactivity_data$Task, reactivity_data$Direction), mean)
##set up the IOC data
colnames(JOL1)[4] = "JOL"
colnames(JOL1)[2] = "Recall"
IOC_data = melt(JOL1, measure.vars = c("JOL", "Recall"))
colnames(IOC_data)[3] = "Task"
colnames(IOC_data)[4] = "Score"
length(unique(IOC_data$id)) #49 Participants in the JOL group
####IOC ANOVA####
model1 = ezANOVA(data = IOC_data,
dv = Score,
wid = id,
within = .(Direction, Task),
return_aov = T,
type = 3,
detailed = T)
model1 #IOC replicates
#Get MSE here
model1$ANOVA$MSE = model1$ANOVA$SSd/model1$ANOVA$DFd
model1$ANOVA$MSE
aovEffectSize(model1, effectSize = "pes")
aovEffectSize(model1, effectSize = "pes")
